{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c27c31c-0ef3-4923-b1f9-104e49653f70",
   "metadata": {},
   "source": [
    "## API Pull Code\n",
    "Author: Kathryn Meldrum (kmm4ap@virginia.edu)\n",
    "\n",
    "to request trial info from clinicaltrials.gov api and convert to pd dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47d40ef-e795-41a1-9aab-8c281ff653d6",
   "metadata": {},
   "source": [
    "possible fields: https://clinicaltrials.gov/api/info/study_fields_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f589ccb-8efa-43c4-bd10-372e7c360dc1",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a278f13b-8a00-4cdb-a01a-e9aa7c8efb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import sys\n",
    "if sys.version_info[0] < 3: \n",
    "    from StringIO import StringIO\n",
    "else:\n",
    "    from io import StringIO\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0578349e-8e04-4078-bb03-3ae832f9677d",
   "metadata": {},
   "source": [
    "## Define Function to pull csv from clinicaltrials.gov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0481dab7-4c2d-43dc-8773-eab144abf393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As Function: \n",
    "def api_pull(min_rnk,max_rnk,fields):\n",
    "    '''\n",
    "    min_rnk: STR NUMBER newest trial to request (1 is newest in database)\n",
    "    max_rnk: STR NUMBER oldest trial to request\n",
    "    fields: STR fields to request separated by comma in single string\n",
    "    '''\n",
    "    #define url structure\n",
    "    api_url='https://clinicaltrials.gov/api/query/study_fields?%20&fields='+fields+'&min_rnk='+min_rnk+'&max_rnk='+max_rnk+'&fmt=csv'\n",
    "    r = requests.get(api_url) #request from api\n",
    "    table=StringIO(str(r.text).split('\\n\\n')[1]) #delete API header and convert to string IO\n",
    "    table=pd.read_csv(table) # convert to pd dataframe\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f12d13-222f-4b23-be8b-ab483fb60cb3",
   "metadata": {},
   "source": [
    "Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb721624-8dda-49cd-ae57-aad59b9b51ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>BriefTitle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Supplementing Brief Psychotherapy With a Mobil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A Study of RC198 in Patients With Locally Adva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Music for Sleep After Stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Effect of Music on Nursing Students' Skills, A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Effect of Early Postoperative Oral Carbohydrat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>Stent Omission After Ureteroscopy and Lithotri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>Use of Clomiphene Citrate as an Inhibitor of O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>A Phase 1 Dose Escalation Study of VX-973 in H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>Boosting Psychotherapy Effects by Means of Tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>Study of the Key Techniques of Prevention and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                                         BriefTitle\n",
       "0      1  Supplementing Brief Psychotherapy With a Mobil...\n",
       "1      2  A Study of RC198 in Patients With Locally Adva...\n",
       "2      3                       Music for Sleep After Stroke\n",
       "3      4  Effect of Music on Nursing Students' Skills, A...\n",
       "4      5  Effect of Early Postoperative Oral Carbohydrat...\n",
       "..   ...                                                ...\n",
       "95    96  Stent Omission After Ureteroscopy and Lithotri...\n",
       "96    97  Use of Clomiphene Citrate as an Inhibitor of O...\n",
       "97    98  A Phase 1 Dose Escalation Study of VX-973 in H...\n",
       "98    99  Boosting Psychotherapy Effects by Means of Tra...\n",
       "99   100  Study of the Key Techniques of Prevention and ...\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_pull('1','100','BriefTitle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba8bd94-a595-49b1-b56e-2fa6900c1541",
   "metadata": {},
   "source": [
    "## Define function to get the number of trials currently on CTG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb7f5b63-b0a7-4a4c-a0c5-432e08dcaa37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "452745"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_num_trials():\n",
    "    '''\n",
    "    Returns the number of trials currently availible from clinicaltrials.gov\n",
    "    '''\n",
    "    api_url='https://clinicaltrials.gov/api/query/study_fields?%20&fields=BriefTitle&min_rnk=1&max_rnk=10&fmt=csv'\n",
    "    r = requests.get(api_url)\n",
    "    return int(str(r.text).split('NStudiesAvail:')[1].split('\"\\n')[0])\n",
    "get_num_trials()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc2893b-178a-4fa2-b936-74d6132835b5",
   "metadata": {},
   "source": [
    "## Load Custom NER Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7bc47b5-26e5-481f-b7e0-5ac521d18cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meldrumapple/anaconda3/lib/python3.10/site-packages/spacy/util.py:877: UserWarning: [W095] Model 'en_pipeline' (0.0.0) was trained with spaCy v3.5 and may not be 100% compatible with the current version (3.4.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "# load in model\n",
    "import spacy\n",
    "nlp=spacy.load('/Users/meldrumapple/Desktop/Capstone/mod_chia/model-best')\n",
    "\n",
    "# set up dict to store spans\n",
    "label_list=['Person','Condition','Drug','Observation','Measurement','Procedure','Device','Visit','Negation','Qualifier','Temporal','Value','Multiplier','Reference_point','Mood','Post-eligibility','Pregnancy_considerations','Informed_consent']\n",
    "ents_dict={}\n",
    "for label in label_list:\n",
    "    ents_dict[label]=[]\n",
    "#print(ents_dict)\n",
    "\n",
    "# define funtion to get labels and spans for 2 columns of text, return lists of labels and spans\n",
    "def analyze(inc, exc):\n",
    "    ents_col=[]\n",
    "    spans_col=[]\n",
    "    text_col=[]\n",
    "    \n",
    "    for (txt1, txt2) in zip(inc, exc):\n",
    "        \n",
    "        ents=[]\n",
    "        spans=[]\n",
    "        \n",
    "        \n",
    "        txt1=str(txt1).replace('|', ' ')\n",
    "        txt2=str(txt2).replace('|', ' ')\n",
    "        \n",
    "        doc1=nlp(str(txt1))\n",
    "        pred_ents1 = [(e.start_char, e.end_char, e.label_) for e in doc1.ents]\n",
    "        for (start, end, label) in pred_ents1:\n",
    "            ents.append(label)\n",
    "            spans.append(txt1[start:end].lower())\n",
    "            ents_dict[label].append(txt1[start:end].lower())\n",
    "            \n",
    "        if txt2 != None: \n",
    "            doc2=nlp(str(txt2))\n",
    "            pred_ents2 = [(e.start_char, e.end_char, e.label_) for e in doc2.ents]\n",
    "            for (start, end, label) in pred_ents2:\n",
    "                ents.append(label)\n",
    "                spans.append(txt2[start:end].lower())\n",
    "                ents_dict[label].append(txt2[start:end].lower())\n",
    "        text_col.append(str('Inclusion Criteria: '+txt1+r'\\n'+' Exclusion Criteria: '+txt2))     \n",
    "        ents_col.append(ents)\n",
    "        spans_col.append(spans)\n",
    "    return (text_col, ents_col, spans_col)\n",
    "\n",
    "# define funtion to get labels and spans for two columns of text, return entity dictionary\n",
    "def analyze2(inc, exc):\n",
    "    inc_col=[]\n",
    "    exc_col=[]\n",
    "    \n",
    "    for (txt1, txt2) in zip(inc, exc):\n",
    "        \n",
    "        txt1=str(txt1).replace('|', ' ')\n",
    "        txt2=str(txt2).replace('|', ' ')\n",
    "        \n",
    "        doc1=nlp(str(txt1))\n",
    "        pred_ents_inc = [(e.start_char, e.end_char, e.label_) for e in doc1.ents]\n",
    "        inc_col.append({'text': txt1, 'entities': pred_ents_inc})\n",
    "            \n",
    "        if txt2 != None: \n",
    "            doc2=nlp(str(txt2))\n",
    "            pred_ents_exc=[(e.start_char, e.end_char, e.label_) for e in doc2.ents]\n",
    "        else: \n",
    "            pred_ents_exc=pd.NA\n",
    "        exc_col.append({'text': txt1, 'entities': pred_ents_inc})\n",
    "        \n",
    "    return (inc_col, exc_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5006d17b-1cb2-484a-8a60-fab56b49cd7b",
   "metadata": {},
   "source": [
    "## Define function to concat trial info and NER Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bbb6123e-ca08-4b1c-ad4b-4262f1b9a56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df():\n",
    "    # define fields to pull:\n",
    "    fields='NCTId,OfficialTitle,OrgFullName,CompletionDate,CompletionDateType,Condition,InterventionType,MinimumAge,MaximumAge,Gender,HealthyVolunteers,EligibilityCriteria'\n",
    "    # define max rank to pull\n",
    "    mx=get_num_trials()\n",
    "    # divide into batches of 1000\n",
    "    x=mx//1000\n",
    "    # initialize dataframe\n",
    "    df = pd.DataFrame(columns=['NCTId','OfficialTitle','OrgFullName','CompletionDate', 'CompletionDateType','Condition','InterventionType','MinimumAge','MaximumAge','Gender','HealthyVolunteers','CriteriaText','Entities','Spans'])\n",
    "    \n",
    "    #helper function to clean chunk\n",
    "    def clean_chunk(chunk):\n",
    "        # split eligibility into inclusion and exclusion\n",
    "        chunk[['InclusionCriteria', 'ExclusionCriteria']]=chunk.EligibilityCriteria.str[21:].str.split(\"Exclusion Criteria:\\\\|\\\\|\",expand=True).iloc[:,:2]\n",
    "        # perform nlp analysis and store\n",
    "        chunk_nlp=analyze(chunk['InclusionCriteria'], chunk['ExclusionCriteria'])\n",
    "        chunk['CriteriaText']=chunk_nlp[0]\n",
    "        chunk['Entities']=chunk_nlp[1]\n",
    "        chunk['Spans']=chunk_nlp[2]\n",
    "        # drop cols we don't want\n",
    "        chunk=chunk.drop(['EligibilityCriteria','InclusionCriteria', 'ExclusionCriteria', 'Rank'], axis=1)\n",
    "        return chunk\n",
    "        \n",
    "\n",
    "    for i in range(0, x):\n",
    "        \n",
    "        # define ranks to pull\n",
    "        min_rnk=str((i*1000)+1)\n",
    "        max_rnk=str((i+1)*1000)\n",
    "        print(min_rnk, max_rnk)\n",
    "        \n",
    "        # pull ranks \n",
    "        chunk=api_pull(min_rnk,max_rnk,fields) \n",
    "        chunk=clean_chunk(chunk)\n",
    "    \n",
    "        # add to big dataframe\n",
    "        df=pd.concat([df, chunk], axis=0)\n",
    "    #get new trials from remainder\n",
    "    chunk=api_pull(str((x*1000)+1), str(mx), fields)\n",
    "    chunk=clean_chunk(chunk)\n",
    "    df=pd.concat([df,chunk], axis=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5500f49-5e58-4c31-b448-1ba7e57b29ab",
   "metadata": {},
   "source": [
    "## Alternate concat function with only NER results and sparse trial info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fedf652c-e81b-405e-a75a-d1708167f972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df2(): #this one pulls entity span indexes\n",
    "    # define fields to pull:\n",
    "    fields='NCTId,OfficialTitle,CompletionDate,EligibilityCriteria'\n",
    "    # define max rank to pull\n",
    "    mx=get_num_trials()\n",
    "    # divide into batches of 1000\n",
    "    x=mx//1000\n",
    "    # initialize dataframe\n",
    "    df = pd.DataFrame(columns=['NCTId','OfficialTitle','CompletionDate','InclusionNER', 'ExclusionNER'])\n",
    "    \n",
    "    #helper function to clean chunk\n",
    "    def clean_chunk(chunk):\n",
    "        # split eligibility into inclusion and exclusion\n",
    "        chunk[['InclusionCriteria', 'ExclusionCriteria']]=chunk.EligibilityCriteria.str[21:].str.split(\"Exclusion Criteria:\\\\|\\\\|\",expand=True).iloc[:,:2]\n",
    "        # perform nlp analysis and store\n",
    "        chunk_nlp=analyze2(chunk['InclusionCriteria'], chunk['ExclusionCriteria'])\n",
    "        chunk['InclusionNER']=chunk_nlp[0]\n",
    "        chunk['ExclusionNER']=chunk_nlp[1]\n",
    "        chunk=chunk.drop(['EligibilityCriteria', 'InclusionCriteria', 'ExclusionCriteria'], axis=1)\n",
    "        return chunk\n",
    "        \n",
    "\n",
    "    for i in range(0, x):\n",
    "        \n",
    "        # define ranks to pull\n",
    "        min_rnk=str((i*1000)+1)\n",
    "        max_rnk=str((i+1)*1000)\n",
    "        print(min_rnk, max_rnk)\n",
    "        \n",
    "        # pull ranks \n",
    "        chunk=api_pull(min_rnk,max_rnk,fields) \n",
    "        chunk=clean_chunk(chunk)\n",
    "    \n",
    "        # add to big dataframe\n",
    "        df=pd.concat([df, chunk], axis=0)\n",
    "    #get new trials from remainder\n",
    "    chunk=api_pull(str((x*1000)+1), str(mx), fields)\n",
    "    chunk=clean_chunk(chunk)\n",
    "    df=pd.concat([df,chunk], axis=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c149e2b-7a22-46a3-adda-ffafda875155",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "36671a54-9c0c-417a-832d-2029df6a5ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get streamlit-style dataframe\n",
    "# st=time.time()\n",
    "# data_set=get_df()\n",
    "# et=time.time()\n",
    "# print('Time Elapsed: '+str(et-st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8197089c-7c49-4487-aa5c-5ce5195514aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data_set.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "266c6fd2-0877-4535-a67e-6748600bcdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_set.to_csv('/Users/meldrumapple/Desktop/Capstone/api_pull_data_sl.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0aab0ab6-30dc-4f1f-b962-d099b1f6a1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(pd.read_csv('/Users/meldrumapple/Desktop/Capstone/api_pull_data_sl.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "42e21643-bf59-4a9d-a401-01996a8ed765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a padded style dataframe with all possible spans for entity types for streamlit\n",
    "# set_ents_dict={}\n",
    "# longest=0\n",
    "# for x in ents_dict.keys():\n",
    "#     if len(list(set(ents_dict[x])))>longest:\n",
    "#         longest=len(list(set(ents_dict[x])))\n",
    "# for x in ents_dict.keys():\n",
    "#     spans=list(set(ents_dict[x]))\n",
    "#     pad=longest-len(spans)\n",
    "#     set_ents_dict[x]=list(set(ents_dict[x]))+[pd.NA]*pad\n",
    "# ents_df=pd.DataFrame(set_ents_dict)\n",
    "# ents_df.to_csv('/Users/meldrumapple/Desktop/Capstone/ents_spans_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f6c67ac9-f825-42e5-abdc-077efab2afd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1000\n",
      "1001 2000\n",
      "2001 3000\n",
      "3001 4000\n",
      "4001 5000\n",
      "5001 6000\n",
      "6001 7000\n",
      "7001 8000\n",
      "8001 9000\n",
      "9001 10000\n",
      "10001 11000\n",
      "11001 12000\n",
      "12001 13000\n",
      "13001 14000\n",
      "14001 15000\n",
      "15001 16000\n",
      "16001 17000\n",
      "17001 18000\n",
      "18001 19000\n",
      "19001 20000\n",
      "20001 21000\n",
      "21001 22000\n",
      "22001 23000\n",
      "23001 24000\n",
      "24001 25000\n",
      "25001 26000\n",
      "26001 27000\n",
      "27001 28000\n",
      "28001 29000\n",
      "29001 30000\n",
      "30001 31000\n",
      "31001 32000\n",
      "32001 33000\n",
      "33001 34000\n",
      "34001 35000\n",
      "35001 36000\n",
      "36001 37000\n",
      "37001 38000\n",
      "38001 39000\n",
      "39001 40000\n",
      "40001 41000\n",
      "41001 42000\n",
      "42001 43000\n",
      "43001 44000\n",
      "44001 45000\n",
      "45001 46000\n",
      "46001 47000\n",
      "47001 48000\n",
      "48001 49000\n",
      "49001 50000\n",
      "50001 51000\n",
      "51001 52000\n",
      "52001 53000\n",
      "53001 54000\n",
      "54001 55000\n",
      "55001 56000\n",
      "56001 57000\n",
      "57001 58000\n",
      "58001 59000\n",
      "59001 60000\n",
      "60001 61000\n",
      "61001 62000\n",
      "62001 63000\n",
      "63001 64000\n",
      "64001 65000\n",
      "65001 66000\n",
      "66001 67000\n",
      "67001 68000\n",
      "68001 69000\n",
      "69001 70000\n",
      "70001 71000\n",
      "71001 72000\n",
      "72001 73000\n",
      "73001 74000\n",
      "74001 75000\n",
      "75001 76000\n",
      "76001 77000\n",
      "77001 78000\n",
      "78001 79000\n",
      "79001 80000\n",
      "80001 81000\n",
      "81001 82000\n",
      "82001 83000\n",
      "83001 84000\n",
      "84001 85000\n",
      "85001 86000\n",
      "86001 87000\n",
      "87001 88000\n",
      "88001 89000\n",
      "89001 90000\n",
      "90001 91000\n",
      "91001 92000\n",
      "92001 93000\n",
      "93001 94000\n",
      "94001 95000\n",
      "95001 96000\n",
      "96001 97000\n",
      "97001 98000\n",
      "98001 99000\n",
      "99001 100000\n",
      "100001 101000\n",
      "101001 102000\n",
      "102001 103000\n",
      "103001 104000\n",
      "104001 105000\n",
      "105001 106000\n",
      "106001 107000\n",
      "107001 108000\n",
      "108001 109000\n",
      "109001 110000\n",
      "110001 111000\n",
      "111001 112000\n",
      "112001 113000\n",
      "113001 114000\n",
      "114001 115000\n",
      "115001 116000\n",
      "116001 117000\n",
      "117001 118000\n",
      "118001 119000\n",
      "119001 120000\n",
      "120001 121000\n",
      "121001 122000\n",
      "122001 123000\n",
      "123001 124000\n",
      "124001 125000\n",
      "125001 126000\n",
      "126001 127000\n",
      "127001 128000\n",
      "128001 129000\n",
      "129001 130000\n",
      "130001 131000\n",
      "131001 132000\n",
      "132001 133000\n",
      "133001 134000\n",
      "134001 135000\n",
      "135001 136000\n",
      "136001 137000\n",
      "137001 138000\n",
      "138001 139000\n",
      "139001 140000\n",
      "140001 141000\n",
      "141001 142000\n",
      "142001 143000\n",
      "143001 144000\n",
      "144001 145000\n",
      "145001 146000\n",
      "146001 147000\n",
      "147001 148000\n",
      "148001 149000\n",
      "149001 150000\n",
      "150001 151000\n",
      "151001 152000\n",
      "152001 153000\n",
      "153001 154000\n",
      "154001 155000\n",
      "155001 156000\n",
      "156001 157000\n",
      "157001 158000\n",
      "158001 159000\n",
      "159001 160000\n",
      "160001 161000\n",
      "161001 162000\n",
      "162001 163000\n",
      "163001 164000\n",
      "164001 165000\n",
      "165001 166000\n",
      "166001 167000\n",
      "167001 168000\n",
      "168001 169000\n",
      "169001 170000\n",
      "170001 171000\n",
      "171001 172000\n",
      "172001 173000\n",
      "173001 174000\n",
      "174001 175000\n",
      "175001 176000\n",
      "176001 177000\n",
      "177001 178000\n",
      "178001 179000\n",
      "179001 180000\n",
      "180001 181000\n",
      "181001 182000\n",
      "182001 183000\n",
      "183001 184000\n",
      "184001 185000\n",
      "185001 186000\n",
      "186001 187000\n",
      "187001 188000\n",
      "188001 189000\n",
      "189001 190000\n",
      "190001 191000\n",
      "191001 192000\n",
      "192001 193000\n",
      "193001 194000\n",
      "194001 195000\n",
      "195001 196000\n",
      "196001 197000\n",
      "197001 198000\n",
      "198001 199000\n",
      "199001 200000\n",
      "200001 201000\n",
      "201001 202000\n",
      "202001 203000\n",
      "203001 204000\n",
      "204001 205000\n",
      "205001 206000\n",
      "206001 207000\n",
      "207001 208000\n",
      "208001 209000\n",
      "209001 210000\n",
      "210001 211000\n",
      "211001 212000\n",
      "212001 213000\n",
      "213001 214000\n",
      "214001 215000\n",
      "215001 216000\n",
      "216001 217000\n",
      "217001 218000\n",
      "218001 219000\n",
      "219001 220000\n",
      "220001 221000\n",
      "221001 222000\n",
      "222001 223000\n",
      "223001 224000\n",
      "224001 225000\n",
      "225001 226000\n",
      "226001 227000\n",
      "227001 228000\n",
      "228001 229000\n",
      "229001 230000\n",
      "230001 231000\n",
      "231001 232000\n",
      "232001 233000\n",
      "233001 234000\n",
      "234001 235000\n",
      "235001 236000\n",
      "236001 237000\n",
      "237001 238000\n",
      "238001 239000\n",
      "239001 240000\n",
      "240001 241000\n",
      "241001 242000\n",
      "242001 243000\n",
      "243001 244000\n",
      "244001 245000\n",
      "245001 246000\n",
      "246001 247000\n",
      "247001 248000\n",
      "248001 249000\n",
      "249001 250000\n",
      "250001 251000\n",
      "251001 252000\n",
      "252001 253000\n",
      "253001 254000\n",
      "254001 255000\n",
      "255001 256000\n",
      "256001 257000\n",
      "257001 258000\n",
      "258001 259000\n",
      "259001 260000\n",
      "260001 261000\n",
      "261001 262000\n",
      "262001 263000\n",
      "263001 264000\n",
      "264001 265000\n",
      "265001 266000\n",
      "266001 267000\n",
      "267001 268000\n",
      "268001 269000\n",
      "269001 270000\n",
      "270001 271000\n",
      "271001 272000\n",
      "272001 273000\n",
      "273001 274000\n",
      "274001 275000\n",
      "275001 276000\n",
      "276001 277000\n",
      "277001 278000\n",
      "278001 279000\n",
      "279001 280000\n",
      "280001 281000\n",
      "281001 282000\n",
      "282001 283000\n",
      "283001 284000\n",
      "284001 285000\n",
      "285001 286000\n",
      "286001 287000\n",
      "287001 288000\n",
      "288001 289000\n",
      "289001 290000\n",
      "290001 291000\n",
      "291001 292000\n",
      "292001 293000\n",
      "293001 294000\n",
      "294001 295000\n",
      "295001 296000\n",
      "296001 297000\n",
      "297001 298000\n",
      "298001 299000\n",
      "299001 300000\n",
      "300001 301000\n",
      "301001 302000\n",
      "302001 303000\n",
      "303001 304000\n",
      "304001 305000\n",
      "305001 306000\n",
      "306001 307000\n",
      "307001 308000\n",
      "308001 309000\n",
      "309001 310000\n",
      "310001 311000\n",
      "311001 312000\n",
      "312001 313000\n",
      "313001 314000\n",
      "314001 315000\n",
      "315001 316000\n",
      "316001 317000\n",
      "317001 318000\n",
      "318001 319000\n",
      "319001 320000\n",
      "320001 321000\n",
      "321001 322000\n",
      "322001 323000\n",
      "323001 324000\n",
      "324001 325000\n",
      "325001 326000\n",
      "326001 327000\n",
      "327001 328000\n",
      "328001 329000\n",
      "329001 330000\n",
      "330001 331000\n",
      "331001 332000\n",
      "332001 333000\n",
      "333001 334000\n",
      "334001 335000\n",
      "335001 336000\n",
      "336001 337000\n",
      "337001 338000\n",
      "338001 339000\n",
      "339001 340000\n",
      "340001 341000\n",
      "341001 342000\n",
      "342001 343000\n",
      "343001 344000\n",
      "344001 345000\n",
      "345001 346000\n",
      "346001 347000\n",
      "347001 348000\n",
      "348001 349000\n",
      "349001 350000\n",
      "350001 351000\n",
      "351001 352000\n",
      "352001 353000\n",
      "353001 354000\n",
      "354001 355000\n",
      "355001 356000\n",
      "356001 357000\n",
      "357001 358000\n",
      "358001 359000\n",
      "359001 360000\n",
      "360001 361000\n",
      "361001 362000\n",
      "362001 363000\n",
      "363001 364000\n",
      "364001 365000\n",
      "365001 366000\n",
      "366001 367000\n",
      "367001 368000\n",
      "368001 369000\n",
      "369001 370000\n",
      "370001 371000\n",
      "371001 372000\n",
      "372001 373000\n",
      "373001 374000\n",
      "374001 375000\n",
      "375001 376000\n",
      "376001 377000\n",
      "377001 378000\n",
      "378001 379000\n",
      "379001 380000\n",
      "380001 381000\n",
      "381001 382000\n",
      "382001 383000\n",
      "383001 384000\n",
      "384001 385000\n",
      "385001 386000\n",
      "386001 387000\n",
      "387001 388000\n",
      "388001 389000\n",
      "389001 390000\n",
      "390001 391000\n",
      "391001 392000\n",
      "392001 393000\n",
      "393001 394000\n",
      "394001 395000\n",
      "395001 396000\n",
      "396001 397000\n",
      "397001 398000\n",
      "398001 399000\n",
      "399001 400000\n",
      "400001 401000\n",
      "401001 402000\n",
      "402001 403000\n",
      "403001 404000\n",
      "404001 405000\n",
      "405001 406000\n",
      "406001 407000\n",
      "407001 408000\n",
      "408001 409000\n",
      "409001 410000\n",
      "410001 411000\n",
      "411001 412000\n",
      "412001 413000\n",
      "413001 414000\n",
      "414001 415000\n",
      "415001 416000\n",
      "416001 417000\n",
      "417001 418000\n",
      "418001 419000\n",
      "419001 420000\n",
      "420001 421000\n",
      "421001 422000\n",
      "422001 423000\n",
      "423001 424000\n",
      "424001 425000\n",
      "425001 426000\n",
      "426001 427000\n",
      "427001 428000\n",
      "428001 429000\n",
      "429001 430000\n",
      "430001 431000\n",
      "431001 432000\n",
      "432001 433000\n",
      "433001 434000\n",
      "434001 435000\n",
      "435001 436000\n",
      "436001 437000\n",
      "437001 438000\n",
      "438001 439000\n",
      "439001 440000\n",
      "440001 441000\n",
      "441001 442000\n",
      "442001 443000\n",
      "443001 444000\n",
      "444001 445000\n",
      "445001 446000\n",
      "446001 447000\n",
      "447001 448000\n",
      "448001 449000\n",
      "449001 450000\n",
      "450001 451000\n",
      "451001 452000\n",
      "Time Elapsed: 9079.197357177734\n",
      "         NCTId                                      OfficialTitle   \n",
      "0  NCT05867316  Supplementing Brief Psychotherapy With a Mobil...  \\\n",
      "1  NCT05867303  A Phase 1, First-in-Human, Multicenter, Open-L...   \n",
      "2  NCT05867290  Mindful Music-listening to as a Tool to Improv...   \n",
      "3  NCT05867277  The Effect of Music on Nursing Students' Skill...   \n",
      "4  NCT05867264  Effect of Early Postoperative Oral Carbohydrat...   \n",
      "\n",
      "       CompletionDate                                       InclusionNER   \n",
      "0      March 30, 2024  {'text': 'Adult status (18+ years) Admission t...  \\\n",
      "1  September 30, 2024  {'text': 'Subjects with the ability to underst...   \n",
      "2   December 31, 2023  {'text': 'aged 18+ (no upper age limit); clini...   \n",
      "3      April 11, 2022  {'text': 'Taking the Nursing Fundamentals Cour...   \n",
      "4   December 30, 2024  {'text': 'Age 18-79 years. Patients undergoing...   \n",
      "\n",
      "                                        ExclusionNER  Rank  \n",
      "0  {'text': 'Adult status (18+ years) Admission t...   1.0  \n",
      "1  {'text': 'Subjects with the ability to underst...   2.0  \n",
      "2  {'text': 'aged 18+ (no upper age limit); clini...   3.0  \n",
      "3  {'text': 'Taking the Nursing Fundamentals Cour...   4.0  \n",
      "4  {'text': 'Age 18-79 years. Patients undergoing...   5.0  \n",
      "452745\n",
      "452745\n"
     ]
    }
   ],
   "source": [
    "# Get results dataframe\n",
    "st=time.time()\n",
    "data_set=get_df2()\n",
    "et=time.time()\n",
    "data_set.to_csv('/Users/meldrumapple/Desktop/Capstone/results.csv')\n",
    "print('Time Elapsed: '+str(et-st))\n",
    "print(data_set.head())\n",
    "print(len(data_set))\n",
    "print(len(pd.read_csv('/Users/meldrumapple/Desktop/Capstone/results.csv')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f063fc-1fb6-4df9-a708-4b963a6a8e57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
